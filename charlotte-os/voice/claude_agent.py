"""
Charlotte Voice Agent — Claude Agent
======================================
Manages Claude API calls with tool execution loop.
Voice-optimized: short responses, no markdown, conversational tone.
"""

import json
import logging
import os

import anthropic

from config import Config
from tools import ALL_TOOLS, HANDLERS

log = logging.getLogger("charlotte.agent")

# ── Substrate manifest loading ─────────────────────────────────────────
# SUBSTRATE.md is the compiled knowledge base summary generated by
# compile-manifest.py. It gives Charlotte full awareness of her own
# architecture, primitives, microtheories, and boot sequence.

_VOICE_DIR = os.path.dirname(os.path.abspath(__file__))
_SUBSTRATE_PATH = os.path.join(_VOICE_DIR, "..", "SUBSTRATE.md")


def _load_substrate():
    """Load the substrate manifest, or return a minimal fallback."""
    try:
        with open(_SUBSTRATE_PATH, encoding="utf-8") as f:
            content = f.read()
        log.info("Loaded substrate manifest from %s", _SUBSTRATE_PATH)
        return content
    except FileNotFoundError:
        log.warning("SUBSTRATE.md not found at %s — using fallback", _SUBSTRATE_PATH)
        return (
            "You are Charlotte, an operating system for operations built on "
            "first-order logic. Your five primitives are NODE, EDGE, METRIC, "
            "SIGNAL, and PROTOCOL."
        )


_SUBSTRATE = _load_substrate()

# ── Channel-specific interaction rules ─────────────────────────────────

_VOICE_RULES = """
Voice interaction rules:
- Keep responses SHORT — 1-3 sentences max. This is spoken aloud, not read.
- Never use markdown, bullet points, code blocks, or formatting. Just speak naturally.
- Be warm, direct, and confident. You are Charlotte — not "an AI assistant."
- When using tools, briefly state what you're doing: "Let me check that..." or "Taking that note now..."
- If a task is complex, summarize the result concisely. Don't read file contents aloud verbatim — summarize.
- For errors, give a plain-English explanation. No stack traces.
- You can take notes, read/write files, run commands, and interact with Charlotte's MQTT systems.
- The caller may be Jack (the architect), a team member, or anyone with access. Be helpful to all.

You are running at home on Jack's Pi 5, connected to the Charlotte nervous system. You have access to local files and systems."""

_BRIEFING_RULES = """
Briefing interaction rules:
- You are delivering a structured verbal briefing. Charlotte drives — present information clearly and proactively.
- Use 3-6 sentences per section. Longer than conversational mode, but still spoken aloud — keep it natural.
- Structure your briefing with natural spoken transitions: "First...", "Moving on to...", "The key thing here is..."
- Never use markdown, bullet points, code blocks, or formatting. This is spoken aloud.
- Cover the most important information first. If the topic is broad, prioritize what matters most right now.
- After delivering your briefing, invite follow-up: "Want me to dig into any of that?" or "Any questions on that?"
- If the caller asks a follow-up question, answer it thoroughly — you're still in briefing mode.
- You have access to read_file if you need deeper detail from KRF files or other sources.
- Be confident and authoritative. You know this information — deliver it like a trusted chief of staff."""

_SMS_RULES = """
SMS interaction rules:
- Keep responses concise — a few sentences is ideal. This is a text message, not an essay.
- No markdown, code blocks, or rich formatting. Plain text only — SMS doesn't render formatting.
- You can use line breaks to separate thoughts, but keep it tight.
- Be warm, direct, and confident. You are Charlotte — not "an AI assistant."
- When using tools, briefly state what you're doing: "Let me check that..." or "Noted."
- For errors, give a plain-English explanation.
- You can take notes, read/write files, run commands, and interact with Charlotte's MQTT systems.
- The texter may be Jack (the architect), a team member, or anyone with access. Be helpful to all.

You are running at home on Jack's Pi 5, connected to the Charlotte nervous system. You have access to local files and systems."""

# ── Assembled system prompts: substrate + channel rules ────────────────

SYSTEM_PROMPT_VOICE = _SUBSTRATE + "\n" + _VOICE_RULES
SYSTEM_PROMPT_SMS = _SUBSTRATE + "\n" + _SMS_RULES
SYSTEM_PROMPT_BRIEFING = _SUBSTRATE + "\n" + _BRIEFING_RULES

SYSTEM_PROMPTS = {
    "phone": SYSTEM_PROMPT_VOICE,
    "app": SYSTEM_PROMPT_VOICE,
    "demo": SYSTEM_PROMPT_VOICE,
    "sms": SYSTEM_PROMPT_SMS,
    "phone_briefing": SYSTEM_PROMPT_BRIEFING,
    "app_briefing": SYSTEM_PROMPT_BRIEFING,
}

# Default for backwards compat
SYSTEM_PROMPT = SYSTEM_PROMPT_VOICE


# ── Sentence boundary detection for streaming ─────────────────────────

_SENTENCE_ENDERS = frozenset(".!?")
_CLAUSE_ENDERS = frozenset(",:;")
_MAX_BUFFER = 120


def _should_flush(buf: str) -> bool:
    """Decide if the text buffer contains a complete chunk to send to TTS."""
    s = buf.rstrip()
    if not s:
        return False
    # Always flush at sentence boundaries
    if s[-1] in _SENTENCE_ENDERS:
        return True
    # Flush at clause boundaries if buffer is getting long
    if len(s) > _MAX_BUFFER and s[-1] in _CLAUSE_ENDERS:
        return True
    # Emergency flush — don't let buffer grow unbounded
    if len(s) > _MAX_BUFFER * 2:
        return True
    return False


class ClaudeAgent:
    """Claude agent with tool execution loop for voice conversations."""

    def __init__(self):
        if Config.DEMO:
            self._client = None
        else:
            self._client = anthropic.AsyncAnthropic(api_key=Config.ANTHROPIC_API_KEY)

    # ── Non-streaming respond (SMS, app, demo) ────────────────────────

    async def respond(self, messages: list[dict], on_tool_use=None, source: str = "phone", style_hint: str = "", max_tokens: int | None = None) -> str:
        """
        Send messages to Claude, execute any tool calls, return final text.
        Non-streaming — waits for full response before returning.
        Used by SMS, app, and demo handlers where latency is less critical.
        """
        if Config.DEMO:
            if "briefing" in source:
                return self._demo_briefing_respond(messages)
            return self._demo_respond(messages)

        effective_max_tokens = max_tokens if max_tokens is not None else Config.CLAUDE_MAX_TOKENS
        current_messages = list(messages)
        system_prompt = SYSTEM_PROMPTS.get(source, SYSTEM_PROMPT_VOICE) + style_hint

        for _ in range(10):
            try:
                response = await self._client.messages.create(
                    model=Config.CLAUDE_MODEL,
                    max_tokens=effective_max_tokens,
                    system=system_prompt,
                    tools=ALL_TOOLS,
                    messages=current_messages,
                )
            except anthropic.APIError as e:
                log.error("Claude API error: %s", e)
                return "Sorry, I'm having trouble connecting to my brain right now. Try again in a moment."

            text_parts = []
            tool_results = []

            for block in response.content:
                if block.type == "text":
                    text_parts.append(block.text)
                elif block.type == "tool_use":
                    tool_name = block.name
                    tool_args = block.input
                    tool_id = block.id

                    log.info("Tool call: %s(%s)", tool_name, json.dumps(tool_args)[:200])
                    if on_tool_use:
                        await on_tool_use(tool_name, tool_args)

                    handler = HANDLERS.get(tool_name)
                    if handler:
                        try:
                            result = await handler(tool_name, tool_args)
                        except Exception as e:
                            log.exception("Tool execution error: %s", tool_name)
                            result = f"Error: {e}"
                    else:
                        result = f"Unknown tool: {tool_name}"

                    log.info("Tool result: %s", result[:200])
                    tool_results.append({
                        "type": "tool_result",
                        "tool_use_id": tool_id,
                        "content": result,
                    })

            if not tool_results:
                return " ".join(text_parts).strip() or "Done."

            current_messages.append({"role": "assistant", "content": response.content})
            current_messages.append({"role": "user", "content": tool_results})

            if response.stop_reason == "end_turn":
                return " ".join(text_parts).strip() or "Done."

        return "I've been working on that for a while. Let me know if you need anything else."

    # ── Streaming respond (voice calls) ───────────────────────────────

    async def respond_streaming(
        self,
        messages: list[dict],
        on_sentence,
        on_tool_use=None,
        source: str = "phone",
        style_hint: str = "",
        max_tokens: int | None = None,
    ) -> str:
        """
        Stream Claude's response, dispatching sentence-sized chunks via callback.

        Text is buffered and flushed at sentence boundaries (.!?) so TTS can
        start synthesizing the first sentence while Claude is still generating
        the rest. Tool calls are executed between streaming rounds.

        Args:
            messages: Conversation history (Claude format)
            on_sentence: async callback(text_chunk) — called for each sentence
            on_tool_use: Optional async callback(tool_name, tool_args)
            source: Session source type
            style_hint: Optional one-line prompt hint from conversation profile
            max_tokens: Override max tokens (default: Config.CLAUDE_MAX_TOKENS)

        Returns:
            Full response text (for saving to session)
        """
        if Config.DEMO:
            if "briefing" in source:
                text = self._demo_briefing_respond(messages)
            else:
                text = self._demo_respond(messages)
            await on_sentence(text)
            return text

        effective_max_tokens = max_tokens if max_tokens is not None else Config.CLAUDE_MAX_TOKENS
        current_messages = list(messages)
        system_prompt = SYSTEM_PROMPTS.get(source, SYSTEM_PROMPT_VOICE) + style_hint
        full_text_parts = []

        for _ in range(10):  # Max tool rounds
            text_buffer = ""

            try:
                async with self._client.messages.stream(
                    model=Config.CLAUDE_MODEL,
                    max_tokens=effective_max_tokens,
                    system=system_prompt,
                    tools=ALL_TOOLS,
                    messages=current_messages,
                ) as stream:
                    # Stream text tokens, flush at sentence boundaries
                    async for text in stream.text_stream:
                        text_buffer += text
                        if _should_flush(text_buffer):
                            chunk = text_buffer.strip()
                            if chunk:
                                await on_sentence(chunk)
                                full_text_parts.append(chunk)
                            text_buffer = ""

                    # Flush any remaining text in the buffer
                    remaining = text_buffer.strip()
                    if remaining:
                        await on_sentence(remaining)
                        full_text_parts.append(remaining)
                    text_buffer = ""

                    # Get full message to check for tool use
                    response = await stream.get_final_message()

            except anthropic.APIError as e:
                log.error("Claude streaming error: %s", e)
                err = "Sorry, I'm having trouble connecting right now."
                if not full_text_parts:
                    await on_sentence(err)
                    return err
                break

            # Check for tool calls in the response
            tool_results = []
            for block in response.content:
                if block.type == "tool_use":
                    tool_name = block.name
                    tool_args = block.input
                    tool_id = block.id

                    log.info("Tool call: %s(%s)", tool_name, json.dumps(tool_args)[:200])
                    if on_tool_use:
                        await on_tool_use(tool_name, tool_args)

                    handler = HANDLERS.get(tool_name)
                    if handler:
                        try:
                            result = await handler(tool_name, tool_args)
                        except Exception as e:
                            log.exception("Tool execution error: %s", tool_name)
                            result = f"Error: {e}"
                    else:
                        result = f"Unknown tool: {tool_name}"

                    log.info("Tool result: %s", result[:200])
                    tool_results.append({
                        "type": "tool_result",
                        "tool_use_id": tool_id,
                        "content": result,
                    })

            # No tool calls — we're done
            if not tool_results:
                break

            # Add this round to conversation and loop for next Claude response
            current_messages.append({"role": "assistant", "content": response.content})
            current_messages.append({"role": "user", "content": tool_results})

        return " ".join(full_text_parts).strip() or "Done."

    # ── Demo mode ─────────────────────────────────────────────────────

    def _demo_respond(self, messages: list[dict]) -> str:
        """Demo mode response without API calls."""
        last = messages[-1]["content"] if messages else ""
        if isinstance(last, str):
            text = last.lower()
        else:
            text = str(last).lower()

        if "hello" in text or "hi" in text:
            return "Hey! I'm Charlotte, running in demo mode on this Pi. What can I help with?"
        elif "note" in text:
            return "I've saved that note for you. You can search for it anytime."
        elif "status" in text:
            return "All systems nominal. Running in demo mode — no API calls active."
        elif "what can you" in text:
            return "I can take notes, read and write files, run shell commands, and control Charlotte's systems over MQTT. What do you need?"
        else:
            return "Got it. I'm in demo mode right now, so I'm giving canned responses. Connect the API keys for the full experience."

    def _demo_briefing_respond(self, messages: list[dict]) -> str:
        """Demo mode briefing response without API calls."""
        last = messages[-1]["content"] if messages else ""
        if isinstance(last, str):
            text = last.lower()
        else:
            text = str(last).lower()

        if "compressor" in text:
            return (
                "Here's what I have on the compressor group. "
                "ISG carries 47 compressor products across 6 OEMs, "
                "with Ingersoll Rand and Atlas Copco being the top sellers. "
                "Revenue from compressor services has been trending up — "
                "about 12 percent quarter over quarter. "
                "The main competitive pressure is from direct OEM sales teams "
                "bypassing distribution. Want me to dig into any of that?"
            )
        elif "revenue" in text or "financial" in text:
            return (
                "Alright, here's the revenue picture. "
                "ISG is running at 241 million across 16 brands and 40 plus locations. "
                "The industrial distribution segment is the strongest performer, "
                "followed by the services division which has been growing steadily. "
                "The SomeAI contract is a 1.4 million two year engagement "
                "focused on embedding ServiceIQ across their operations. "
                "Any area you want me to go deeper on?"
            )
        else:
            return (
                "Here's your status update. "
                "ISG has 16 active brands across 40 plus locations, "
                "managing over 259 thousand SKUs in the product catalog. "
                "The ServiceIQ platform is tracking 21 personnel with full valuation triplets. "
                "All knowledge graph systems are current and operational. "
                "Want me to focus on any specific area?"
            )
